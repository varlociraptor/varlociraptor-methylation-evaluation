# Main entrypoint of the workflow.
# Please follow the best practices:
# https://snakemake.readthedocs.io/en/stable/snakefiles/best_practices.html,
# in particular regarding the standardized folder structure mentioned there.


configfile: "config/config.yaml"

scattergather:
    split=8

read_type = config["read_type"]
chr21_config = config["sample"]
accession = config["accession"]


aligned_bam_reads = (
    "resources/aligned-reads-pacbio.bam"
    if read_type == "PacBio"
    else "resources/aligned-reads-illumina.bam"
)

aligned_bam_reads_index = (
    "resources/aligned-reads-pacbio-sorted.bam.bai"
    if read_type == "PacBio"
    else "resources/aligned-reads-illumina-sorted.bam.bai"
)

aligned_sam_reads = (
    "resources/aligned-reads-pacbio.sam"
    if read_type == "PacBio"
    else "resources/aligned-reads-illumina.sam"
)

aligned_bam_reads_sorted = (
    "resources/aligned-reads-pacbio-sorted.bam"
    if read_type == "PacBio"
    else "resources/aligned-reads-illumina-sorted.bam"
)

aligned_sam_reads_sorted = (
    "resources/aligned-reads-pacbio-sorted.sam"
    if read_type == "PacBio"
    else "resources/aligned-reads-illumina-sorted.sam"
)


rule all:
    input:
        tv="results/scatter_plot_tv.png",


rule get_chr21:
    output:
        "resources/genome.fasta",
    params:
        species=chr21_config["species"],
        datatype=chr21_config["datatype"],
        build=chr21_config["build"],
        release=chr21_config["release"],
    log:
        "logs/get_chr21.log",
    cache: "omit-software"  # save space and time with between workflow caching (see docs)
    wrapper:
        "v2.3.2/bio/reference/ensembl-sequence"


rule get_chromosome:
    output:
        "resources/chr21.fasta",
    params:
        species=chr21_config["species"],
        datatype=chr21_config["datatype"],
        build=chr21_config["build"],
        release=chr21_config["release"],
        chromosome=chr21_config["chromosome"],
    log:
        "logs/get_chromosome.log",
    cache: "omit-software"  # save space and time with between workflow caching (see docs)
    wrapper:
        "v2.3.2/bio/reference/ensembl-sequence"

# Maybe samtools supports threads (look it up)
rule chr21_index:
    input:
        "resources/chr21.fasta",
    output:
        "resources/chr21.fasta.fai",
    log:
        "logs/chr21_index.log",
    conda:
        "envs/samtools.yaml"
    params:
        pipeline_path=config["pipeline_path"],
    threads: 10
    shell:
        """ 
        samtools faidx -@ {threads} {params.pipeline_path}{input}
        """


rule find_candidates:
    input:
        "resources/chr21.fasta",
    output:
        "resources/candidates.bcf",
    log:
        "logs/find_candidates.log",
    conda:
        "envs/varlociraptor.yaml"
    params:
        varlo_path=config["varlo_path"],
        pipeline_path=config["pipeline_path"],
    shell:
        """ 
        cd {params.varlo_path}
        cargo run -- methylation-candidates {params.pipeline_path}{input} {params.pipeline_path}{output}
        """



# Unused
rule candidates_to_vcf:
    input:
        "resources/candidates.bcf",
    output:
        "resources/candidates.vcf",
    conda:
        "envs/samtools.yaml"
    log:
        "logs/convert_to_vcf.log",
    threads: 10
    shell:
        """
        bcftools view --threads {threads} {input} > {output}
        """




rule get_fastq_pe:
    output:
        # the wildcard name must be accession, pointing to an SRA number
        "resources/{accession}_1.fastq",
        "resources/{accession}_2.fastq",
    log:
        "logs/pe/{accession}.log"
    params:
        extra="--skip-technical"
    threads: 20  # defaults to 6
    conda:
        "envs/fastq-wrapper.yaml"
    wrapper:
        "v2.6.0/bio/sra-tools/fasterq-dump"


rule align_reads:
    input:
        fasta="resources/chr21.fasta",
        reads1=expand("resources/{accession}_1.fastq", accession=accession),
        reads2=expand("resources/{accession}_2.fastq", accession=accession),
    output:
        aligned_bam_reads,
    conda:
        "envs/bwa-meth.yaml"
    log:
        "logs/align_reads.log",
    threads: 20
    shell:
        """
        bwameth.py index-mem2 {input.fasta}
        bwameth.py --threads {threads} --reference {input.fasta} {input.reads1} {input.reads2}  | samtools view -S -b - > {output}
        """


rule aligned_reads_sorted_sam:
    input:
        aligned_bam_reads,
    output:
        sam_reads=aligned_sam_reads,
        sam_sorted=aligned_sam_reads_sorted,
    log:
        "logs/aligned_reads_sorted_sam.log",
    conda:
        "envs/samtools.yaml"
    params:
        pipeline_path=config["pipeline_path"],
    threads: 10
    shell:
        """ 
        samtools view -@ {threads} -bS {params.pipeline_path}{input} > {params.pipeline_path}/{output.sam_reads}    
        samtools sort -@ {threads} {output.sam_reads} -o {output.sam_sorted}    
        """

rule sort_aligned_reads:
    input:
        aligned_bam_reads,
    output:
        aligned_bam_reads_sorted,
    log:
        "logs/sort_aligned_reads.log",
    conda:
        "envs/samtools.yaml"
    params:
        pipeline_path=config["pipeline_path"],
    threads: 10
    shell:
        """
        samtools sort -@ {threads}  {input} -o {output}    
        """

rule aligned_reads_index:
    input:
        aligned_bam_reads_sorted,
    output:
        aligned_bam_reads_index,
    log:
        "logs/aligned_reads_to_bam.log",
    conda:
        "envs/samtools.yaml"
    params:
        pipeline_path=config["pipeline_path"],
    threads: 10
    shell:
        """
        samtools index -@ {threads} {params.pipeline_path}/{input}
        """

rule methylDackel:
    input:
        chr21="resources/example_new/chr21.fasta",
        alignment=aligned_bam_reads_sorted,
        alignment_index=aligned_bam_reads_index
    output:
        "results/alignments_CpG.bedGraph",
    conda:
        "envs/methylDackel.yaml"
    log:
        "logs/methylDackel.log",
    params:
        pipeline_path=config["pipeline_path"],
    shell:
        """
        MethylDackel extract {input.chr21} {input.alignment} -o {params.pipeline_path}/results/alignments --mergeContext
        """


rule compute_meth_observations:
    input:
        chr21="resources/chr21.fasta",
        chr21_index="resources/chr21.fasta.fai",
        alignments=aligned_bam_reads_sorted,
        alignments_index=aligned_bam_reads_index,
        candidates="resources/candidates.bcf",
    output:
        "results/normal.bcf",
    log:
        "logs/copute.log",
    conda:
        "envs/varlociraptor.yaml"
    params:
        varlo_path=config["varlo_path"],
        pipeline_path=config["pipeline_path"],
        read_type=config["read_type"],
    shell:
        """ 
        cd {params.varlo_path}
        cargo run --release -- preprocess variants {params.pipeline_path}{input.chr21} --candidates {params.pipeline_path}{input.candidates} --bam {params.pipeline_path}{input.alignments} --read-type {params.read_type} > {params.pipeline_path}{output}
        """

# Unused
rule observations_to_vcf:
    input:
        "results/normal.bcf",
    output:
        "results/normal.vcf",
    conda:
        "envs/samtools.yaml"
    log:
        "logs/convert_to_vcf.log",
    threads: 10
    shell:
        """
        bcftools view --threads {threads} {input} > {output}
        """


rule call_methylation:
    input:
        preprocess_obs="results/normal.bcf",
        scenario="resources/scenario.yaml",
    output:
        "results/calls.bcf",
    log:
        "logs/copute.log",
    conda:
        "envs/varlociraptor.yaml"
    params:
        varlo_path=config["varlo_path"],
        pipeline_path=config["pipeline_path"],
        read_type=config["read_type"],
    shell:
        """ 
        cd {params.varlo_path}
        cargo run --release -- call variants --omit-strand-bias generic --scenario {params.pipeline_path}{input.scenario} --obs normal={params.pipeline_path}{input.preprocess_obs} > {params.pipeline_path}/{output}
        """


rule calls_to_vcf:
    input:
        "results/calls.bcf",
    output:
        "results/calls.vcf",
    conda:
        "envs/samtools.yaml"
    log:
        "logs/convert_to_vcf.log",
    threads: 10
    shell:
        """
        bcftools --threads {threads} view {input} -o {output}
        """

rule download_bedGraphs:
    output:
        "resources/HG002/{bedGraph}.bedGraph.gz",
    log:
        "logs/download_bedGraphs{bedGraph}.log",
    params:
        pipeline_path=config["pipeline_path"],
        bedGraphs = config["bedGraphs_HG002"]
    script:
        "scripts/get_bedGraph_data.py"


rule process_data:
    input:
        "resources/HG002/{bedGraph}.bedGraph.gz"
    output:
        "resources/HG002/{bedGraph}.bedGraph"
    log:
        "logs/process_data{bedGraph}.log",
    shell:
        "gunzip -c {input} > {output}"


rule compute_avg_bedGraph:
    input:
        # expand("resources/HG002/bedGraph/{bed}.bedGraph", bed=bedGraphs),
        expand("resources/HG002/{bedGraph}.bedGraph", bedGraph=config["bedGraphs_HG002"])

    output:
        "resources/bed_avg.bedGraph",
    log:
        "logs/compute_avg_bedGraph.log",
    script:
        "scripts/compute_avg_bedGraph.py"


rule plot_results:
    input:
        bedGraph="results/alignments_CpG.bedGraph",
        calls="results/calls.vcf",
        true_meth="resources/bed_avg.bedGraph"
    output:
        tv="results/scatter_plot_tv.png",
    conda:
        "envs/plot.yaml"
    log:
        "logs/plot_results.log",
    script:
        "scripts/scatter_plot.py"
